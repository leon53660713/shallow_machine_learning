{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d58247",
   "metadata": {},
   "source": [
    "# Yale_face_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d9e8a",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f3b910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T04:36:02.496858Z",
     "start_time": "2024-05-12T04:36:02.481808Z"
    }
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "# warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# data\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# visulaize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "# adjust data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# ML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11fb3b",
   "metadata": {},
   "source": [
    "# import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21e7ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:13:21.898022Z",
     "start_time": "2024-05-11T21:13:21.891022Z"
    }
   },
   "outputs": [],
   "source": [
    "# import ML_func.py\n",
    "from ML_func import ml_func\n",
    "func = ml_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14541637",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6337e36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:13:23.795567Z",
     "start_time": "2024-05-11T21:13:23.427553Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "faces_data = loadmat(\"allFaces.mat\")\n",
    "# get x\n",
    "X = faces_data[\"faces\"].T\n",
    "nfaces = faces_data[\"nfaces\"][0]\n",
    "# get y\n",
    "y = np.repeat(np.arange(1, len(nfaces) + 1), nfaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58692a5e",
   "metadata": {},
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071608a",
   "metadata": {},
   "source": [
    "## original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4f1056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:13:25.263814Z",
     "start_time": "2024-05-11T21:13:25.228815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data : 1928\n",
      "testing data : 482\n"
     ]
    }
   ],
   "source": [
    "X_train_original, X_test_original, y_train, y_test = func.preprocess_data(\n",
    "    X, y, 65536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5897c60",
   "metadata": {},
   "source": [
    "## standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee6e7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:13:27.781738Z",
     "start_time": "2024-05-11T21:13:26.681243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardlize training data : 1928\n",
      "standardlize testing data : 482\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = func.preprocess_data(\n",
    "    X, y, 65536, standard=\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85851515",
   "metadata": {},
   "source": [
    "## pca data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf80b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:14:01.875950Z",
     "start_time": "2024-05-11T21:13:28.977101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardlize training data : 1928\n",
      "standardlize testing data : 482\n",
      "finish doing pca\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_pca, X_test_pca, y_train, y_test = func.preprocess_data(\n",
    "    X, y, 65536, standard=\"True\", pca=\"True\", n_pc=0.9, show_plot=\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfefc82",
   "metadata": {},
   "source": [
    "# modeling standardize data\n",
    "把標準化後的資料建模 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c1426",
   "metadata": {},
   "source": [
    "## MLR\n",
    "多元羅吉斯回歸 (Multinomial Logistic Regression) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94749275",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bcf87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T21:15:11.312662Z",
     "start_time": "2024-05-11T21:14:27.204564Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLR model & hyperparametersmodel\n",
    "mlr_opts = dict(multi_class='auto', tol=1e-6, max_iter=int(150), verbose=1)\n",
    "mlr_model = LogisticRegression(**mlr_opts)\n",
    "mlr_model.fit(X_train_scaled, y_train)\n",
    "# predict\n",
    "y_pred_mlr = mlr_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e271b5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T05:46:52.508064Z",
     "start_time": "2024-05-12T05:46:52.424856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">standard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    standard      \n",
       "         MLR      \n",
       "      metric value\n",
       "0   accuracy  0.98\n",
       "1  precision  0.98\n",
       "2     recall  0.98\n",
       "3   F1-score  0.97"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "mlr_eva = func.evaluate_model(y_test, y_pred_mlr)\n",
    "# change to df\n",
    "mlr_df = pd.DataFrame(list(mlr_eva.items()), columns=[\n",
    "                      [\"standard\", \"standard\"], [\"MLR\", \"MLR\"], ['metric', 'value']])\n",
    "mlr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28582e",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c050319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:58:23.807855Z",
     "start_time": "2024-05-12T12:58:23.801244Z"
    }
   },
   "outputs": [],
   "source": [
    "# # search best parameter\n",
    "# param_grid = {\n",
    "#     'C': [0.5, 1],\n",
    "#     'solver': ['newton-cg', 'lbfgs'],\n",
    "#     'penalty': ['l1', 'l2']\n",
    "# }\n",
    "\n",
    "# # model\n",
    "# mlr_opts = dict(multi_class='auto', tol=1e-6, max_iter=int(150), verbose=1)\n",
    "# mlr_model = LogisticRegression(**mlr_opts)\n",
    "\n",
    "# # grid search\n",
    "# grid_search = GridSearchCV(mlr_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # print\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# # predict\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_mlr_best = best_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c2acce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:58:26.539963Z",
     "start_time": "2024-05-12T12:58:26.535448Z"
    }
   },
   "outputs": [],
   "source": [
    "# # evaluation\n",
    "# mlr_eva_best = func.evaluate_model(y_test, y_pred_mlr_best)\n",
    "# # change to df\n",
    "# mlr_df_best = pd.DataFrame(list(mlr_eva_best.items()), columns=[\n",
    "#                       [\"standard\", \"standard\"], [\"MLR\", \"MLR\"], ['metric', 'value']])\n",
    "# mlr_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30400ce0",
   "metadata": {},
   "source": [
    "### MLR conclusion\n",
    "可以發現 default 的效果就已經近乎完美 <br>\n",
    "為了避免麻煩(運行時間過久 : > 30 min) <br>\n",
    "因此使用 default 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f2564",
   "metadata": {},
   "source": [
    "## SVM\n",
    "支援向量機 (Support Vector Machine) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab9224",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50211a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T05:52:28.383801Z",
     "start_time": "2024-05-12T05:47:15.731137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "# SVM model & hyperparameter\n",
    "svm_opts = dict(C=1, tol=1e-6, max_iter=int(1e6), verbose=1)\n",
    "svm_model = SVC(kernel='linear', **svm_opts)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "# predict\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e0e2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T05:54:41.281143Z",
     "start_time": "2024-05-12T05:54:41.252259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">standard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    standard      \n",
       "         SVM      \n",
       "      metric value\n",
       "0   accuracy  0.94\n",
       "1  precision  0.94\n",
       "2     recall  0.94\n",
       "3   F1-score  0.94"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "svm_eva = func.evaluate_model(y_test, y_pred_svm)\n",
    "# change to df\n",
    "svm_df = pd.DataFrame(list(svm_eva.items()), columns=[\n",
    "                      [\"standard\", \"standard\"], [\"SVM\", \"SVM\"], ['metric', 'value']])\n",
    "svm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66301ba",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c00000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search best parameter\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1],\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "# }\n",
    "\n",
    "# # model\n",
    "# svm_opts = dict(tol=1e-6, max_iter=int(1e6))\n",
    "# svm_model = SVC(**svm_opts)\n",
    "\n",
    "# # grid search\n",
    "# grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # print\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# # predict\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_svm_best = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluation\n",
    "# svm_eva_best = func.evaluate_model(y_test, y_pred_svm_best)\n",
    "# # change to df\n",
    "# svm_df_best = pd.DataFrame(list(svm_eva_best.items()), columns=[\n",
    "#                       [\"standard\", \"standard\"], [\"SVM\", \"SVM\"], ['metric', 'value']])\n",
    "# svm_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87761e3",
   "metadata": {},
   "source": [
    "### SVM conclusion\n",
    "可以發現 default 的效果就已經還算不錯 <br>\n",
    "為了避免麻煩(運行時間過久 : > 30 min) <br>\n",
    "因此使用 default 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f561f",
   "metadata": {},
   "source": [
    "## NN--MLP\n",
    "神經網路 (Neural Network) -- 多層感知機 (Multilayer perceptron) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9d4b3",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efea8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:00:56.602117Z",
     "start_time": "2024-05-12T05:56:28.533456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.67098216\n",
      "Iteration 2, loss = 3.52502260\n",
      "Iteration 3, loss = 3.34179706\n",
      "Iteration 4, loss = 3.13571983\n",
      "Iteration 5, loss = 2.92585207\n",
      "Iteration 6, loss = 2.72039130\n",
      "Iteration 7, loss = 2.52689888\n",
      "Iteration 8, loss = 2.34292591\n",
      "Iteration 9, loss = 2.16556291\n",
      "Iteration 10, loss = 2.00070370\n",
      "Iteration 11, loss = 1.85052644\n",
      "Iteration 12, loss = 1.71119978\n",
      "Iteration 13, loss = 1.58328276\n",
      "Iteration 14, loss = 1.46885046\n",
      "Iteration 15, loss = 1.36395925\n",
      "Iteration 16, loss = 1.26749571\n",
      "Iteration 17, loss = 1.17914078\n",
      "Iteration 18, loss = 1.09276264\n",
      "Iteration 19, loss = 1.00920745\n",
      "Iteration 20, loss = 0.93529511\n",
      "Iteration 21, loss = 0.86205718\n",
      "Iteration 22, loss = 0.79306246\n",
      "Iteration 23, loss = 0.73397272\n",
      "Iteration 24, loss = 0.68184504\n",
      "Iteration 25, loss = 0.63086239\n",
      "Iteration 26, loss = 0.58285416\n",
      "Iteration 27, loss = 0.54054672\n",
      "Iteration 28, loss = 0.50000067\n",
      "Iteration 29, loss = 0.46471340\n",
      "Iteration 30, loss = 0.43516379\n",
      "Iteration 31, loss = 0.40513854\n",
      "Iteration 32, loss = 0.37972701\n",
      "Iteration 33, loss = 0.35299533\n",
      "Iteration 34, loss = 0.33360643\n",
      "Iteration 35, loss = 0.31105176\n",
      "Iteration 36, loss = 0.29716427\n",
      "Iteration 37, loss = 0.28018951\n",
      "Iteration 38, loss = 0.26761438\n",
      "Iteration 39, loss = 0.25378127\n",
      "Iteration 40, loss = 0.23593215\n",
      "Iteration 41, loss = 0.22585564\n",
      "Iteration 42, loss = 0.21510415\n",
      "Iteration 43, loss = 0.20444881\n",
      "Iteration 44, loss = 0.19863769\n",
      "Iteration 45, loss = 0.18755147\n",
      "Iteration 46, loss = 0.17978733\n",
      "Iteration 47, loss = 0.17258079\n",
      "Iteration 48, loss = 0.16568549\n",
      "Iteration 49, loss = 0.16005577\n",
      "Iteration 50, loss = 0.15529964\n",
      "Iteration 51, loss = 0.14750267\n",
      "Iteration 52, loss = 0.14289057\n",
      "Iteration 53, loss = 0.13897093\n",
      "Iteration 54, loss = 0.13184214\n",
      "Iteration 55, loss = 0.12806866\n",
      "Iteration 56, loss = 0.12400953\n",
      "Iteration 57, loss = 0.12343069\n",
      "Iteration 58, loss = 0.11638972\n",
      "Iteration 59, loss = 0.11452503\n",
      "Iteration 60, loss = 0.11078676\n",
      "Iteration 61, loss = 0.10691466\n",
      "Iteration 62, loss = 0.10375731\n",
      "Iteration 63, loss = 0.10114398\n",
      "Iteration 64, loss = 0.09866531\n",
      "Iteration 65, loss = 0.09643962\n",
      "Iteration 66, loss = 0.09400029\n",
      "Iteration 67, loss = 0.09062423\n",
      "Iteration 68, loss = 0.08913106\n",
      "Iteration 69, loss = 0.08801434\n",
      "Iteration 70, loss = 0.08496862\n",
      "Iteration 71, loss = 0.08371710\n",
      "Iteration 72, loss = 0.08161561\n",
      "Iteration 73, loss = 0.07945055\n",
      "Iteration 74, loss = 0.07749521\n",
      "Iteration 75, loss = 0.07644907\n",
      "Iteration 76, loss = 0.07415078\n",
      "Iteration 77, loss = 0.07263886\n",
      "Iteration 78, loss = 0.07094043\n",
      "Iteration 79, loss = 0.06993320\n",
      "Iteration 80, loss = 0.06903756\n",
      "Iteration 81, loss = 0.06860984\n",
      "Iteration 82, loss = 0.06639957\n",
      "Iteration 83, loss = 0.06600741\n",
      "Iteration 84, loss = 0.06306651\n",
      "Iteration 85, loss = 0.06221019\n",
      "Iteration 86, loss = 0.06065344\n",
      "Iteration 87, loss = 0.06156091\n",
      "Iteration 88, loss = 0.06092019\n",
      "Iteration 89, loss = 0.05915998\n",
      "Iteration 90, loss = 0.05703776\n",
      "Iteration 91, loss = 0.05729008\n",
      "Iteration 92, loss = 0.05550568\n",
      "Iteration 93, loss = 0.05463010\n",
      "Iteration 94, loss = 0.05373607\n",
      "Iteration 95, loss = 0.05301456\n",
      "Iteration 96, loss = 0.05266081\n",
      "Iteration 97, loss = 0.05365529\n",
      "Iteration 98, loss = 0.05153867\n",
      "Iteration 99, loss = 0.05013650\n",
      "Iteration 100, loss = 0.05026864\n",
      "Iteration 101, loss = 0.04847819\n",
      "Iteration 102, loss = 0.04959749\n",
      "Iteration 103, loss = 0.04813275\n",
      "Iteration 104, loss = 0.04805816\n",
      "Iteration 105, loss = 0.04570924\n",
      "Iteration 106, loss = 0.04647334\n",
      "Iteration 107, loss = 0.04501035\n",
      "Iteration 108, loss = 0.04491913\n",
      "Iteration 109, loss = 0.04455406\n",
      "Iteration 110, loss = 0.04395933\n",
      "Iteration 111, loss = 0.04308670\n",
      "Iteration 112, loss = 0.04237258\n",
      "Iteration 113, loss = 0.04193653\n",
      "Iteration 114, loss = 0.04295624\n",
      "Iteration 115, loss = 0.04053717\n",
      "Iteration 116, loss = 0.04011063\n",
      "Iteration 117, loss = 0.03993987\n",
      "Iteration 118, loss = 0.03989437\n",
      "Iteration 119, loss = 0.03872522\n",
      "Iteration 120, loss = 0.03991718\n",
      "Iteration 121, loss = 0.03866305\n",
      "Iteration 122, loss = 0.03869401\n",
      "Iteration 123, loss = 0.03763276\n",
      "Iteration 124, loss = 0.03776865\n",
      "Iteration 125, loss = 0.03817593\n",
      "Iteration 126, loss = 0.03704524\n",
      "Iteration 127, loss = 0.03585372\n",
      "Iteration 128, loss = 0.03646119\n",
      "Iteration 129, loss = 0.03631865\n",
      "Iteration 130, loss = 0.03570905\n",
      "Iteration 131, loss = 0.03512473\n",
      "Iteration 132, loss = 0.03478620\n",
      "Iteration 133, loss = 0.03500920\n",
      "Iteration 134, loss = 0.03495079\n",
      "Iteration 135, loss = 0.03469864\n",
      "Iteration 136, loss = 0.03330237\n",
      "Iteration 137, loss = 0.03261517\n",
      "Iteration 138, loss = 0.03302102\n",
      "Iteration 139, loss = 0.03198515\n",
      "Iteration 140, loss = 0.03290389\n",
      "Iteration 141, loss = 0.03266340\n",
      "Iteration 142, loss = 0.03178833\n",
      "Iteration 143, loss = 0.03233315\n",
      "Iteration 144, loss = 0.03229057\n",
      "Iteration 145, loss = 0.03102506\n",
      "Iteration 146, loss = 0.03045022\n",
      "Iteration 147, loss = 0.03229961\n",
      "Iteration 148, loss = 0.03038147\n",
      "Iteration 149, loss = 0.03047924\n",
      "Iteration 150, loss = 0.03039239\n",
      "Iteration 151, loss = 0.02986304\n",
      "Iteration 152, loss = 0.03001763\n",
      "Iteration 153, loss = 0.02976962\n",
      "Iteration 154, loss = 0.03065951\n",
      "Iteration 155, loss = 0.03032461\n",
      "Iteration 156, loss = 0.02949027\n",
      "Iteration 157, loss = 0.02796879\n",
      "Iteration 158, loss = 0.02881779\n",
      "Iteration 159, loss = 0.02901334\n",
      "Iteration 160, loss = 0.02882172\n",
      "Iteration 161, loss = 0.02966883\n",
      "Iteration 162, loss = 0.02808718\n",
      "Iteration 163, loss = 0.02737737\n",
      "Iteration 164, loss = 0.02750081\n",
      "Iteration 165, loss = 0.02663751\n",
      "Iteration 166, loss = 0.02707156\n",
      "Iteration 167, loss = 0.02771579\n",
      "Iteration 168, loss = 0.02681150\n",
      "Iteration 169, loss = 0.02568704\n",
      "Iteration 170, loss = 0.02719160\n",
      "Iteration 171, loss = 0.02606638\n",
      "Iteration 172, loss = 0.02650257\n",
      "Iteration 173, loss = 0.02586047\n",
      "Iteration 174, loss = 0.02574456\n",
      "Iteration 175, loss = 0.02531485\n",
      "Iteration 176, loss = 0.02587202\n",
      "Iteration 177, loss = 0.02600193\n",
      "Iteration 178, loss = 0.02583801\n",
      "Iteration 179, loss = 0.02467162\n",
      "Iteration 180, loss = 0.02503928\n",
      "Iteration 181, loss = 0.02560031\n",
      "Iteration 182, loss = 0.02569854\n",
      "Iteration 183, loss = 0.02590732\n",
      "Iteration 184, loss = 0.02535881\n",
      "Iteration 185, loss = 0.02469136\n",
      "Iteration 186, loss = 0.02378583\n",
      "Iteration 187, loss = 0.02416544\n",
      "Iteration 188, loss = 0.02509960\n",
      "Iteration 189, loss = 0.02456349\n",
      "Iteration 190, loss = 0.02328025\n",
      "Iteration 191, loss = 0.02340858\n",
      "Iteration 192, loss = 0.02379655\n",
      "Iteration 193, loss = 0.02342450\n",
      "Iteration 194, loss = 0.02438138\n",
      "Iteration 195, loss = 0.02248578\n",
      "Iteration 196, loss = 0.02435542\n",
      "Iteration 197, loss = 0.02298937\n",
      "Iteration 198, loss = 0.02248511\n",
      "Iteration 199, loss = 0.02218115\n",
      "Iteration 200, loss = 0.02261277\n",
      "Iteration 201, loss = 0.02260204\n",
      "Iteration 202, loss = 0.02220034\n",
      "Iteration 203, loss = 0.02402379\n",
      "Iteration 204, loss = 0.02276986\n",
      "Iteration 205, loss = 0.02190199\n",
      "Iteration 206, loss = 0.02369335\n",
      "Iteration 207, loss = 0.02161025\n",
      "Iteration 208, loss = 0.02302231\n",
      "Iteration 209, loss = 0.02243906\n",
      "Iteration 210, loss = 0.02274435\n",
      "Iteration 211, loss = 0.02222750\n",
      "Iteration 212, loss = 0.02113850\n",
      "Iteration 213, loss = 0.02113535\n",
      "Iteration 214, loss = 0.02112280\n",
      "Iteration 215, loss = 0.02228352\n",
      "Iteration 216, loss = 0.02307479\n",
      "Iteration 217, loss = 0.02083407\n",
      "Iteration 218, loss = 0.02233122\n",
      "Iteration 219, loss = 0.02082983\n",
      "Iteration 220, loss = 0.02204329\n",
      "Iteration 221, loss = 0.02179446\n",
      "Iteration 222, loss = 0.02217076\n",
      "Iteration 223, loss = 0.02120865\n",
      "Iteration 224, loss = 0.02081235\n",
      "Iteration 225, loss = 0.02192118\n",
      "Iteration 226, loss = 0.02324236\n",
      "Iteration 227, loss = 0.02096146\n",
      "Iteration 228, loss = 0.01999256\n",
      "Iteration 229, loss = 0.01973041\n",
      "Iteration 230, loss = 0.02027669\n",
      "Iteration 231, loss = 0.02038350\n",
      "Iteration 232, loss = 0.02156727\n",
      "Iteration 233, loss = 0.02093533\n",
      "Iteration 234, loss = 0.02122366\n",
      "Iteration 235, loss = 0.01962165\n",
      "Iteration 236, loss = 0.02006739\n",
      "Iteration 237, loss = 0.01964811\n",
      "Iteration 238, loss = 0.02025190\n",
      "Iteration 239, loss = 0.02042283\n",
      "Iteration 240, loss = 0.02091630\n",
      "Iteration 241, loss = 0.01941448\n",
      "Iteration 242, loss = 0.01898361\n",
      "Iteration 243, loss = 0.01903713\n",
      "Iteration 244, loss = 0.01937813\n",
      "Iteration 245, loss = 0.01935601\n",
      "Iteration 246, loss = 0.01854742\n",
      "Iteration 247, loss = 0.01886638\n",
      "Iteration 248, loss = 0.01822535\n",
      "Iteration 249, loss = 0.02006585\n",
      "Iteration 250, loss = 0.01923459\n",
      "Iteration 251, loss = 0.01832284\n",
      "Iteration 252, loss = 0.01926542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.01848203\n",
      "Iteration 254, loss = 0.01819954\n",
      "Iteration 255, loss = 0.01909024\n",
      "Iteration 256, loss = 0.01896054\n",
      "Iteration 257, loss = 0.01838679\n",
      "Iteration 258, loss = 0.01851649\n",
      "Iteration 259, loss = 0.01783185\n",
      "Iteration 260, loss = 0.01910626\n",
      "Iteration 261, loss = 0.01822278\n",
      "Iteration 262, loss = 0.01808195\n",
      "Iteration 263, loss = 0.01853680\n",
      "Iteration 264, loss = 0.01848976\n",
      "Iteration 265, loss = 0.01771745\n",
      "Iteration 266, loss = 0.01802820\n",
      "Iteration 267, loss = 0.01769520\n",
      "Iteration 268, loss = 0.01791991\n",
      "Iteration 269, loss = 0.01856461\n",
      "Iteration 270, loss = 0.01830077\n",
      "Iteration 271, loss = 0.01810378\n",
      "Iteration 272, loss = 0.01794715\n",
      "Iteration 273, loss = 0.01835765\n",
      "Iteration 274, loss = 0.01752665\n",
      "Iteration 275, loss = 0.01802528\n",
      "Iteration 276, loss = 0.01771196\n",
      "Iteration 277, loss = 0.01746892\n",
      "Iteration 278, loss = 0.01793487\n",
      "Iteration 279, loss = 0.01841908\n",
      "Iteration 280, loss = 0.01718598\n",
      "Iteration 281, loss = 0.01717274\n",
      "Iteration 282, loss = 0.01649874\n",
      "Iteration 283, loss = 0.01648189\n",
      "Iteration 284, loss = 0.01722996\n",
      "Iteration 285, loss = 0.01684086\n",
      "Iteration 286, loss = 0.01628248\n",
      "Iteration 287, loss = 0.01706418\n",
      "Iteration 288, loss = 0.01749082\n",
      "Iteration 289, loss = 0.01700867\n",
      "Iteration 290, loss = 0.01804251\n",
      "Iteration 291, loss = 0.01685149\n",
      "Iteration 292, loss = 0.01676830\n",
      "Iteration 293, loss = 0.01704520\n",
      "Iteration 294, loss = 0.01803160\n",
      "Iteration 295, loss = 0.01694252\n",
      "Iteration 296, loss = 0.01608860\n",
      "Iteration 297, loss = 0.01685643\n",
      "Iteration 298, loss = 0.01686114\n",
      "Iteration 299, loss = 0.01628307\n",
      "Iteration 300, loss = 0.01722701\n",
      "Iteration 301, loss = 0.01679369\n",
      "Iteration 302, loss = 0.01783658\n",
      "Iteration 303, loss = 0.01603061\n",
      "Iteration 304, loss = 0.01621366\n",
      "Iteration 305, loss = 0.01569440\n",
      "Iteration 306, loss = 0.01612595\n",
      "Iteration 307, loss = 0.01630952\n",
      "Iteration 308, loss = 0.01526144\n",
      "Iteration 309, loss = 0.01621045\n",
      "Iteration 310, loss = 0.01608111\n",
      "Iteration 311, loss = 0.01616134\n",
      "Iteration 312, loss = 0.01565347\n",
      "Iteration 313, loss = 0.01654360\n",
      "Iteration 314, loss = 0.01782763\n",
      "Iteration 315, loss = 0.01603573\n",
      "Iteration 316, loss = 0.01644445\n",
      "Iteration 317, loss = 0.01704883\n",
      "Iteration 318, loss = 0.01543136\n",
      "Iteration 319, loss = 0.01561605\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# NN-MLP model & hyperparameter\n",
    "hidden_layers = (50, 100,120)\n",
    "opts = dict(hidden_layer_sizes=hidden_layers, verbose=1,\n",
    "            activation='relu', tol=1e-6, max_iter=int(1e6))\n",
    "nn_mlp_model = MLPClassifier(solver='sgd', **opts)\n",
    "nn_mlp_model.fit(X_train_scaled, y_train)\n",
    "# predict\n",
    "y_pred_nn_mlp = nn_mlp_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47291c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:01:07.646811Z",
     "start_time": "2024-05-12T06:01:07.623821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">standard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">NN_MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    standard      \n",
       "      NN_MLP      \n",
       "      metric value\n",
       "0   accuracy  0.96\n",
       "1  precision  0.96\n",
       "2     recall  0.96\n",
       "3   F1-score  0.96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "nn_mlp_eva = func.evaluate_model(y_test, y_pred_nn_mlp)\n",
    "# change to df\n",
    "nn_mlp_df = pd.DataFrame(list(nn_mlp_eva.items()), columns=[\n",
    "                         [\"standard\", \"standard\"], [\"NN_MLP\", \"NN_MLP\"], ['metric', 'value']])\n",
    "nn_mlp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a561da6",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f310b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search best parameter\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(50, 100)],\n",
    "#     'activation': ['logistic', 'relu'],\n",
    "#     'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "# }\n",
    "\n",
    "# # model\n",
    "# opts = dict(verbose=1, tol=1e-6, max_iter=int(1e6))\n",
    "# nn_mlp_model = MLPClassifier(**opts)\n",
    "\n",
    "# # grid search\n",
    "# grid_search = GridSearchCV(nn_mlp_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # print\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# # predict\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_nn_mlp_best = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e03ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluation\n",
    "# nn_mlp_eva_best = func.evaluate_model(y_test, y_pred_nn_mlp_best)\n",
    "# # change to df\n",
    "# nn_mlp_df_best = pd.DataFrame(list(nn_mlp_eva_best.items()), columns=[\n",
    "#                          [\"standard\", \"standard\"], [\"NN_MLP\", \"NN_MLP\"], ['metric', 'value']])\n",
    "# nn_mlp_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b7c88",
   "metadata": {},
   "source": [
    "### NN--MLP conclusion\n",
    "可以發現 default 的效果就已經還算不錯 <br>\n",
    "為了避免麻煩(運行時間過久 : > 30 min) <br>\n",
    "因此使用 default 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55e547",
   "metadata": {},
   "source": [
    "## NN--SEQ\n",
    "神經網路 (Neural Network) -- 簡單的線性堆疊模型 <br>\n",
    "一層一層的建立神經網路 <br>\n",
    "接著列出現在構建的網路長甚麼樣子 <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ac9778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:01:14.087452Z",
     "start_time": "2024-05-12T06:01:13.440320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                2064448   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2600      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1312      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 38)                1254      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2069614 (7.89 MB)\n",
      "Trainable params: 2069614 (7.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# change 1~3 to 0~2\n",
    "y_train_nn = y_train-1\n",
    "y_test_nn = y_test-1\n",
    "\n",
    "# model\n",
    "nn_seq_model = Sequential()\n",
    "nn_seq_model.add(Dense(64, activation='relu',\n",
    "                 input_shape=(X_train_scaled.shape[1],)))\n",
    "nn_seq_model.add(Dense(40, activation='relu'))\n",
    "nn_seq_model.add(Dropout(0.2))\n",
    "nn_seq_model.add(Dense(32, activation='relu'))\n",
    "# avoid overfitting\n",
    "# nn_seq_model.add(Dropout(0.2))\n",
    "nn_seq_model.add(Dense(38, activation='softmax'))\n",
    "\n",
    "# compile\n",
    "# set learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "nn_seq_model.compile(optimizer=optimizer,\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# check model\n",
    "nn_seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352ea012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:05:15.046470Z",
     "start_time": "2024-05-12T06:02:25.367503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "49/49 [==============================] - 3s 28ms/step - loss: 7.8221 - accuracy: 0.0435 - val_loss: 4.3615 - val_accuracy: 0.0337\n",
      "Epoch 2/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 4.1213 - accuracy: 0.0837 - val_loss: 3.4937 - val_accuracy: 0.0881\n",
      "Epoch 3/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 3.6060 - accuracy: 0.1109 - val_loss: 3.2617 - val_accuracy: 0.1218\n",
      "Epoch 4/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 3.1927 - accuracy: 0.1654 - val_loss: 2.8971 - val_accuracy: 0.1788\n",
      "Epoch 5/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 2.9328 - accuracy: 0.2082 - val_loss: 2.7631 - val_accuracy: 0.2150\n",
      "Epoch 6/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.7601 - accuracy: 0.2458 - val_loss: 2.6367 - val_accuracy: 0.3057\n",
      "Epoch 7/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.5217 - accuracy: 0.3139 - val_loss: 2.3978 - val_accuracy: 0.3497\n",
      "Epoch 8/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.3563 - accuracy: 0.3573 - val_loss: 2.1343 - val_accuracy: 0.4093\n",
      "Epoch 9/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.1881 - accuracy: 0.4092 - val_loss: 1.9605 - val_accuracy: 0.4845\n",
      "Epoch 10/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.9417 - accuracy: 0.4598 - val_loss: 1.6680 - val_accuracy: 0.5363\n",
      "Epoch 11/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.9853 - accuracy: 0.4468 - val_loss: 1.7344 - val_accuracy: 0.5466\n",
      "Epoch 12/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 1.9182 - accuracy: 0.4643 - val_loss: 1.5158 - val_accuracy: 0.5699\n",
      "Epoch 13/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.7077 - accuracy: 0.5045 - val_loss: 1.5011 - val_accuracy: 0.5803\n",
      "Epoch 14/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.7236 - accuracy: 0.5032 - val_loss: 1.5026 - val_accuracy: 0.5544\n",
      "Epoch 15/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 1.6592 - accuracy: 0.5227 - val_loss: 1.7830 - val_accuracy: 0.5570\n",
      "Epoch 16/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.6689 - accuracy: 0.5350 - val_loss: 1.4210 - val_accuracy: 0.6295\n",
      "Epoch 17/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 1.4187 - accuracy: 0.5921 - val_loss: 1.2131 - val_accuracy: 0.6425\n",
      "Epoch 18/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 1.5108 - accuracy: 0.5765 - val_loss: 1.2800 - val_accuracy: 0.6399\n",
      "Epoch 19/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.4763 - accuracy: 0.5778 - val_loss: 1.0124 - val_accuracy: 0.6917\n",
      "Epoch 20/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.2839 - accuracy: 0.6219 - val_loss: 0.9455 - val_accuracy: 0.7332\n",
      "Epoch 21/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.3639 - accuracy: 0.6180 - val_loss: 1.0977 - val_accuracy: 0.6684\n",
      "Epoch 22/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.1580 - accuracy: 0.6602 - val_loss: 0.9484 - val_accuracy: 0.7047\n",
      "Epoch 23/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 1.1818 - accuracy: 0.6492 - val_loss: 0.8231 - val_accuracy: 0.7487\n",
      "Epoch 24/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 1.1691 - accuracy: 0.6524 - val_loss: 0.8996 - val_accuracy: 0.7461\n",
      "Epoch 25/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 1.2144 - accuracy: 0.6440 - val_loss: 0.9531 - val_accuracy: 0.7202\n",
      "Epoch 26/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 1.2431 - accuracy: 0.6459 - val_loss: 0.9560 - val_accuracy: 0.7098\n",
      "Epoch 27/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 1.1156 - accuracy: 0.6667 - val_loss: 0.8770 - val_accuracy: 0.7280\n",
      "Epoch 28/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.9480 - accuracy: 0.7147 - val_loss: 0.8410 - val_accuracy: 0.7409\n",
      "Epoch 29/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.9484 - accuracy: 0.7101 - val_loss: 0.7801 - val_accuracy: 0.7642\n",
      "Epoch 30/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.9743 - accuracy: 0.7147 - val_loss: 0.6829 - val_accuracy: 0.7850\n",
      "Epoch 31/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.9404 - accuracy: 0.7270 - val_loss: 0.6509 - val_accuracy: 0.8109\n",
      "Epoch 32/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.8608 - accuracy: 0.7458 - val_loss: 0.6349 - val_accuracy: 0.8005\n",
      "Epoch 33/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.9525 - accuracy: 0.7231 - val_loss: 0.8229 - val_accuracy: 0.7565\n",
      "Epoch 34/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.8249 - accuracy: 0.7497 - val_loss: 0.7199 - val_accuracy: 0.7772\n",
      "Epoch 35/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.9469 - accuracy: 0.7134 - val_loss: 0.6379 - val_accuracy: 0.8161\n",
      "Epoch 36/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.7926 - accuracy: 0.7626 - val_loss: 0.7509 - val_accuracy: 0.7824\n",
      "Epoch 37/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.8461 - accuracy: 0.7568 - val_loss: 0.6705 - val_accuracy: 0.8005\n",
      "Epoch 38/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.9914 - accuracy: 0.7121 - val_loss: 0.7899 - val_accuracy: 0.7746\n",
      "Epoch 39/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.9293 - accuracy: 0.7237 - val_loss: 0.8111 - val_accuracy: 0.7850\n",
      "Epoch 40/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.8556 - accuracy: 0.7678 - val_loss: 0.6632 - val_accuracy: 0.8031\n",
      "Epoch 41/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.7190 - accuracy: 0.7866 - val_loss: 0.4788 - val_accuracy: 0.8653\n",
      "Epoch 42/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.6879 - accuracy: 0.7931 - val_loss: 0.4243 - val_accuracy: 0.8756\n",
      "Epoch 43/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.7186 - accuracy: 0.7769 - val_loss: 0.6786 - val_accuracy: 0.8005\n",
      "Epoch 44/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.6592 - accuracy: 0.8106 - val_loss: 0.5501 - val_accuracy: 0.8368\n",
      "Epoch 45/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.6595 - accuracy: 0.8003 - val_loss: 0.5978 - val_accuracy: 0.8238\n",
      "Epoch 46/150\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.6865 - accuracy: 0.8061 - val_loss: 0.5008 - val_accuracy: 0.8601\n",
      "Epoch 47/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.7551 - accuracy: 0.7763 - val_loss: 0.5282 - val_accuracy: 0.8446\n",
      "Epoch 48/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.7221 - accuracy: 0.7899 - val_loss: 0.5791 - val_accuracy: 0.8472\n",
      "Epoch 49/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.7266 - accuracy: 0.7931 - val_loss: 0.6099 - val_accuracy: 0.8497\n",
      "Epoch 50/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.7168 - accuracy: 0.7892 - val_loss: 0.5583 - val_accuracy: 0.8420\n",
      "Epoch 51/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.6654 - accuracy: 0.8022 - val_loss: 0.5517 - val_accuracy: 0.8575\n",
      "Epoch 52/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.5796 - accuracy: 0.8256 - val_loss: 0.4484 - val_accuracy: 0.8731\n",
      "Epoch 53/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.6000 - accuracy: 0.8204 - val_loss: 0.4673 - val_accuracy: 0.8705\n",
      "Epoch 54/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5489 - accuracy: 0.8424 - val_loss: 0.5448 - val_accuracy: 0.8472\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 21ms/step - loss: 0.6896 - accuracy: 0.8003 - val_loss: 0.7062 - val_accuracy: 0.8394\n",
      "Epoch 56/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.6504 - accuracy: 0.8093 - val_loss: 0.5606 - val_accuracy: 0.8472\n",
      "Epoch 57/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5877 - accuracy: 0.8333 - val_loss: 0.5394 - val_accuracy: 0.8679\n",
      "Epoch 58/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.5996 - accuracy: 0.8204 - val_loss: 0.4624 - val_accuracy: 0.8808\n",
      "Epoch 59/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.6554 - accuracy: 0.8113 - val_loss: 0.5697 - val_accuracy: 0.8575\n",
      "Epoch 60/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.5447 - accuracy: 0.8411 - val_loss: 0.5064 - val_accuracy: 0.8679\n",
      "Epoch 61/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5696 - accuracy: 0.8256 - val_loss: 0.3584 - val_accuracy: 0.8886\n",
      "Epoch 62/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.4943 - accuracy: 0.8567 - val_loss: 0.5712 - val_accuracy: 0.8446\n",
      "Epoch 63/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5450 - accuracy: 0.8463 - val_loss: 0.5446 - val_accuracy: 0.8601\n",
      "Epoch 64/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5062 - accuracy: 0.8333 - val_loss: 0.4681 - val_accuracy: 0.8756\n",
      "Epoch 65/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.5284 - accuracy: 0.8411 - val_loss: 0.3917 - val_accuracy: 0.8938\n",
      "Epoch 66/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.4471 - accuracy: 0.8593 - val_loss: 0.3682 - val_accuracy: 0.9119\n",
      "Epoch 67/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.5505 - accuracy: 0.8418 - val_loss: 0.3706 - val_accuracy: 0.8886\n",
      "Epoch 68/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.4894 - accuracy: 0.8619 - val_loss: 0.4222 - val_accuracy: 0.8964\n",
      "Epoch 69/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4615 - accuracy: 0.8696 - val_loss: 0.4540 - val_accuracy: 0.8860\n",
      "Epoch 70/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4776 - accuracy: 0.8567 - val_loss: 0.4503 - val_accuracy: 0.8653\n",
      "Epoch 71/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.6103 - accuracy: 0.8275 - val_loss: 0.5450 - val_accuracy: 0.8420\n",
      "Epoch 72/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.4670 - accuracy: 0.8612 - val_loss: 0.3370 - val_accuracy: 0.9223\n",
      "Epoch 73/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.5326 - accuracy: 0.8450 - val_loss: 0.3864 - val_accuracy: 0.8808\n",
      "Epoch 74/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.5236 - accuracy: 0.8444 - val_loss: 0.4716 - val_accuracy: 0.8627\n",
      "Epoch 75/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.4587 - accuracy: 0.8638 - val_loss: 0.3287 - val_accuracy: 0.8964\n",
      "Epoch 76/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4574 - accuracy: 0.8593 - val_loss: 0.4171 - val_accuracy: 0.8808\n",
      "Epoch 77/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.4992 - accuracy: 0.8703 - val_loss: 0.3777 - val_accuracy: 0.8860\n",
      "Epoch 78/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.7947 - accuracy: 0.7918 - val_loss: 0.5160 - val_accuracy: 0.8394\n",
      "Epoch 79/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.5740 - accuracy: 0.8275 - val_loss: 0.4075 - val_accuracy: 0.8756\n",
      "Epoch 80/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4746 - accuracy: 0.8586 - val_loss: 0.3378 - val_accuracy: 0.9041\n",
      "Epoch 81/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.6508 - accuracy: 0.8061 - val_loss: 0.4939 - val_accuracy: 0.8653\n",
      "Epoch 82/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.4844 - accuracy: 0.8541 - val_loss: 0.4027 - val_accuracy: 0.8756\n",
      "Epoch 83/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4749 - accuracy: 0.8638 - val_loss: 0.3701 - val_accuracy: 0.8860\n",
      "Epoch 84/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4136 - accuracy: 0.8748 - val_loss: 0.3317 - val_accuracy: 0.9016\n",
      "Epoch 85/150\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.4107 - accuracy: 0.8787 - val_loss: 0.3641 - val_accuracy: 0.9067\n",
      "Epoch 86/150\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.4355 - accuracy: 0.8755 - val_loss: 0.3386 - val_accuracy: 0.9016\n",
      "Epoch 87/150\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.3436 - accuracy: 0.9008 - val_loss: 0.3707 - val_accuracy: 0.9041\n",
      "Epoch 88/150\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.4191 - accuracy: 0.8923 - val_loss: 0.3985 - val_accuracy: 0.8705\n",
      "Epoch 89/150\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.4851 - accuracy: 0.8567 - val_loss: 0.3442 - val_accuracy: 0.9016\n",
      "Epoch 90/150\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.4022 - accuracy: 0.8846 - val_loss: 0.2951 - val_accuracy: 0.8990\n",
      "Epoch 91/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.3398 - accuracy: 0.8936 - val_loss: 0.3217 - val_accuracy: 0.9145\n",
      "Epoch 92/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.4198 - accuracy: 0.8768 - val_loss: 0.2385 - val_accuracy: 0.9326\n",
      "Epoch 93/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.3081 - accuracy: 0.9125 - val_loss: 0.3728 - val_accuracy: 0.9171\n",
      "Epoch 94/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.4263 - accuracy: 0.8794 - val_loss: 0.3259 - val_accuracy: 0.9171\n",
      "Epoch 95/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3956 - accuracy: 0.8904 - val_loss: 0.5368 - val_accuracy: 0.8834\n",
      "Epoch 96/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.5550 - accuracy: 0.8515 - val_loss: 0.6043 - val_accuracy: 0.8653\n",
      "Epoch 97/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.6010 - accuracy: 0.8340 - val_loss: 0.3787 - val_accuracy: 0.8938\n",
      "Epoch 98/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.4023 - accuracy: 0.8787 - val_loss: 0.2886 - val_accuracy: 0.9093\n",
      "Epoch 99/150\n",
      "49/49 [==============================] - 1s 19ms/step - loss: 0.3399 - accuracy: 0.8943 - val_loss: 0.2583 - val_accuracy: 0.9249\n",
      "Epoch 100/150\n",
      "49/49 [==============================] - 1s 19ms/step - loss: 0.2982 - accuracy: 0.9086 - val_loss: 0.2487 - val_accuracy: 0.9301\n",
      "Epoch 101/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.3548 - accuracy: 0.8969 - val_loss: 0.3200 - val_accuracy: 0.9016\n",
      "Epoch 102/150\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.4188 - accuracy: 0.8722 - val_loss: 0.2599 - val_accuracy: 0.9326\n",
      "Epoch 103/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3482 - accuracy: 0.8975 - val_loss: 0.2548 - val_accuracy: 0.9249\n",
      "Epoch 104/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3184 - accuracy: 0.9092 - val_loss: 0.3830 - val_accuracy: 0.9093\n",
      "Epoch 105/150\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.3436 - accuracy: 0.9008 - val_loss: 0.3258 - val_accuracy: 0.9093\n",
      "Epoch 106/150\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.3588 - accuracy: 0.8898 - val_loss: 0.2887 - val_accuracy: 0.9093\n",
      "Epoch 107/150\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.3139 - accuracy: 0.9034 - val_loss: 0.2690 - val_accuracy: 0.9301\n",
      "Epoch 108/150\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.3724 - accuracy: 0.8995 - val_loss: 0.3602 - val_accuracy: 0.9249\n",
      "Epoch 109/150\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.3128 - accuracy: 0.9066 - val_loss: 0.2721 - val_accuracy: 0.9249\n",
      "Epoch 110/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.3042 - accuracy: 0.9099 - val_loss: 0.3201 - val_accuracy: 0.9197\n",
      "Epoch 111/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2975 - accuracy: 0.9137 - val_loss: 0.2359 - val_accuracy: 0.9249\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2519 - accuracy: 0.9215 - val_loss: 0.2360 - val_accuracy: 0.9197\n",
      "Epoch 113/150\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.2797 - accuracy: 0.9157 - val_loss: 0.2373 - val_accuracy: 0.9301\n",
      "Epoch 114/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2979 - accuracy: 0.9073 - val_loss: 0.2304 - val_accuracy: 0.9249\n",
      "Epoch 115/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.2718 - accuracy: 0.9228 - val_loss: 0.3433 - val_accuracy: 0.9093\n",
      "Epoch 116/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2891 - accuracy: 0.9215 - val_loss: 0.3894 - val_accuracy: 0.8964\n",
      "Epoch 117/150\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.3433 - accuracy: 0.9040 - val_loss: 0.3026 - val_accuracy: 0.9197\n",
      "Epoch 118/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.2798 - accuracy: 0.9170 - val_loss: 0.2601 - val_accuracy: 0.9301\n",
      "Epoch 119/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.3348 - accuracy: 0.9066 - val_loss: 0.2687 - val_accuracy: 0.9119\n",
      "Epoch 120/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3737 - accuracy: 0.8930 - val_loss: 0.3456 - val_accuracy: 0.9067\n",
      "Epoch 121/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3024 - accuracy: 0.9112 - val_loss: 0.2659 - val_accuracy: 0.9093\n",
      "Epoch 122/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3316 - accuracy: 0.9086 - val_loss: 0.2637 - val_accuracy: 0.9275\n",
      "Epoch 123/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.3308 - accuracy: 0.9008 - val_loss: 0.3684 - val_accuracy: 0.9119\n",
      "Epoch 124/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3467 - accuracy: 0.8995 - val_loss: 0.3165 - val_accuracy: 0.9093\n",
      "Epoch 125/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4024 - accuracy: 0.8872 - val_loss: 0.4214 - val_accuracy: 0.8990\n",
      "Epoch 126/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4419 - accuracy: 0.8690 - val_loss: 0.4493 - val_accuracy: 0.8756\n",
      "Epoch 127/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.4463 - accuracy: 0.8800 - val_loss: 0.3460 - val_accuracy: 0.9249\n",
      "Epoch 128/150\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2945 - accuracy: 0.9112 - val_loss: 0.2998 - val_accuracy: 0.9171\n",
      "Epoch 129/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3511 - accuracy: 0.8969 - val_loss: 0.3354 - val_accuracy: 0.9041\n",
      "Epoch 130/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.2592 - accuracy: 0.9228 - val_loss: 0.3013 - val_accuracy: 0.9223\n",
      "Epoch 131/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.2934 - accuracy: 0.9163 - val_loss: 0.3055 - val_accuracy: 0.9119\n",
      "Epoch 132/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.2717 - accuracy: 0.9163 - val_loss: 0.2348 - val_accuracy: 0.9249\n",
      "Epoch 133/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.2959 - accuracy: 0.9066 - val_loss: 0.3952 - val_accuracy: 0.9041\n",
      "Epoch 134/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3586 - accuracy: 0.8956 - val_loss: 0.4374 - val_accuracy: 0.8731\n",
      "Epoch 135/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3448 - accuracy: 0.8982 - val_loss: 0.2401 - val_accuracy: 0.9275\n",
      "Epoch 136/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3673 - accuracy: 0.8995 - val_loss: 0.2473 - val_accuracy: 0.9352\n",
      "Epoch 137/150\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.3321 - accuracy: 0.8975 - val_loss: 0.3586 - val_accuracy: 0.8990\n",
      "Epoch 138/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.3500 - accuracy: 0.8936 - val_loss: 0.2559 - val_accuracy: 0.9249\n",
      "Epoch 139/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3092 - accuracy: 0.9137 - val_loss: 0.2662 - val_accuracy: 0.9275\n",
      "Epoch 140/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.3228 - accuracy: 0.9034 - val_loss: 0.2881 - val_accuracy: 0.9119\n",
      "Epoch 141/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.4345 - accuracy: 0.8982 - val_loss: 0.2992 - val_accuracy: 0.9223\n",
      "Epoch 142/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3213 - accuracy: 0.9099 - val_loss: 0.2614 - val_accuracy: 0.9326\n",
      "Epoch 143/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3070 - accuracy: 0.9144 - val_loss: 0.2889 - val_accuracy: 0.9119\n",
      "Epoch 144/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3565 - accuracy: 0.9053 - val_loss: 0.2815 - val_accuracy: 0.9223\n",
      "Epoch 145/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.3157 - accuracy: 0.9034 - val_loss: 0.2869 - val_accuracy: 0.9249\n",
      "Epoch 146/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.2820 - accuracy: 0.9222 - val_loss: 0.2799 - val_accuracy: 0.9326\n",
      "Epoch 147/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.2796 - accuracy: 0.9189 - val_loss: 0.2966 - val_accuracy: 0.9145\n",
      "Epoch 148/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3361 - accuracy: 0.9060 - val_loss: 0.3797 - val_accuracy: 0.9067\n",
      "Epoch 149/150\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.4448 - accuracy: 0.8852 - val_loss: 0.3721 - val_accuracy: 0.9119\n",
      "Epoch 150/150\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.3784 - accuracy: 0.8969 - val_loss: 0.3070 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = nn_seq_model.fit(X_train_scaled, y_train_nn,\n",
    "                           epochs=150, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88277814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:06:37.144509Z",
     "start_time": "2024-05-12T06:06:36.787834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.385423868894577\n",
      "accuracy : 0.9066389799118042\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_loss, test_accuracy = nn_seq_model.evaluate(\n",
    "    X_test_scaled, y_test_nn, verbose=0)\n",
    "y_pred_prob = nn_seq_model.predict(X_test_scaled, verbose=0)\n",
    "y_pred_nn_seq = np.argmax(y_pred_prob, axis=1)\n",
    "print(\"loss :\", test_loss)\n",
    "print(\"accuracy :\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c62872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:06:37.708827Z",
     "start_time": "2024-05-12T06:06:37.675828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">standard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">NN_SEQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    standard      \n",
       "      NN_SEQ      \n",
       "      metric value\n",
       "0   accuracy  0.91\n",
       "1  precision  0.92\n",
       "2     recall  0.91\n",
       "3   F1-score  0.91"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "nn_seq_eva = func.evaluate_model(y_test_nn, y_pred_nn_seq)\n",
    "# change to df\n",
    "nn_seq_df = pd.DataFrame(list(nn_seq_eva.items()), columns=[\n",
    "                         [\"standard\", \"standard\"], [\"NN_SEQ\", \"NN_SEQ\"], ['metric', 'value']])\n",
    "nn_seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291fa88",
   "metadata": {},
   "source": [
    "## compare evaluation of standardize data\n",
    "把上述所有的評估指標組合一起觀察 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b75ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:06:42.528050Z",
     "start_time": "2024-05-12T06:06:42.511050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">standard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MLR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN_MLP</th>\n",
       "      <th>NN_SEQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          standard                    \n",
       "               MLR   SVM NN_MLP NN_SEQ\n",
       "             value value  value  value\n",
       "metric                                \n",
       "accuracy      0.98  0.94   0.96   0.91\n",
       "precision     0.98  0.94   0.96   0.92\n",
       "recall        0.98  0.94   0.96   0.91\n",
       "F1-score      0.97  0.94   0.96   0.91"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine df together\n",
    "mlr_df_copy = mlr_df.copy()\n",
    "svm_df_copy = svm_df.copy()\n",
    "nn_mlp_df_copy = nn_mlp_df.copy()\n",
    "nn_seq_df_copy = nn_seq_df.copy()\n",
    "# del same col\n",
    "svm_df_copy.drop((\"standard\", \"SVM\", \"metric\"), axis=1, inplace=True)\n",
    "nn_mlp_df_copy.drop((\"standard\", \"NN_MLP\", \"metric\"), axis=1, inplace=True)\n",
    "nn_seq_df_copy.drop((\"standard\", \"NN_SEQ\", \"metric\"), axis=1, inplace=True)\n",
    "\n",
    "# combine\n",
    "final_df_standard = pd.concat(\n",
    "    [mlr_df_copy, svm_df_copy, nn_mlp_df_copy, nn_seq_df_copy], axis=1)\n",
    "# set \"metric\" to index\n",
    "final_df_standard.set_index((\"standard\", \"MLR\", \"metric\"), inplace=True)\n",
    "final_df_standard = final_df_standard.rename_axis(\"metric\")\n",
    "\n",
    "# show\n",
    "final_df_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6296555",
   "metadata": {},
   "source": [
    "## model of standardize data conclusion\n",
    "可以看出總體來說 MLR 模型的表現是最好的 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d786c",
   "metadata": {},
   "source": [
    "# modeling pca data\n",
    "把 PCA 後的資料建模 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f486da",
   "metadata": {},
   "source": [
    "## MLR\n",
    "多元羅吉斯回歸 (Multinomial Logistic Regression) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b234f27",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1990d8a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:11:48.086376Z",
     "start_time": "2024-05-12T06:11:44.193886Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLR model & hyperparametersmodel\n",
    "mlr_opts = dict(multi_class='auto',C = 0.1, tol=1e-6, max_iter=int(1e6), verbose=1)\n",
    "mlr_model = LogisticRegression(**mlr_opts)\n",
    "mlr_model.fit(X_train_pca, y_train)\n",
    "# predict\n",
    "y_pred_mlr = mlr_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10393349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:11:48.197383Z",
     "start_time": "2024-05-12T06:11:48.167389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "         MLR      \n",
       "      metric value\n",
       "0   accuracy  0.88\n",
       "1  precision  0.89\n",
       "2     recall  0.88\n",
       "3   F1-score  0.88"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "mlr_eva = func.evaluate_model(y_test, y_pred_mlr)\n",
    "# change to df\n",
    "mlr_df = pd.DataFrame(list(mlr_eva.items()), columns=[\n",
    "                      [\"PCA\", \"PCA\"], [\"MLR\", \"MLR\"], ['metric', 'value']])\n",
    "mlr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903baee",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c72c650a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:21:32.036938Z",
     "start_time": "2024-05-12T06:14:46.253994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters found:  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# search best parameter\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'solver': ['newton-cg', 'lbfgs'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# model\n",
    "mlr_opts = dict(multi_class='auto', tol=1e-6, max_iter=int(1e6), verbose=1)\n",
    "mlr_model = LogisticRegression(**mlr_opts)\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(mlr_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# print\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_mlr_best = best_model.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5a2205a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:21:32.148925Z",
     "start_time": "2024-05-12T06:21:32.119925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MLR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "         MLR      \n",
       "      metric value\n",
       "0   accuracy  0.88\n",
       "1  precision  0.89\n",
       "2     recall  0.88\n",
       "3   F1-score  0.88"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "mlr_eva_best = func.evaluate_model(y_test, y_pred_mlr_best)\n",
    "# change to df\n",
    "mlr_df_best = pd.DataFrame(list(mlr_eva_best.items()), columns=[\n",
    "                      [\"PCA\", \"PCA\"], [\"MLR\", \"MLR\"], ['metric', 'value']])\n",
    "mlr_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609f7a5",
   "metadata": {},
   "source": [
    "### MLR conclusion\n",
    "可以發現 2個的結果相同 <br>\n",
    "為了避免麻煩 <br>\n",
    "因此使用 default 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129d275",
   "metadata": {},
   "source": [
    "## SVM\n",
    "支援向量機 (Support Vector Machine) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c85ac8",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b2a623e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:31:49.414393Z",
     "start_time": "2024-05-12T06:31:49.085048Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM model & hyperparameter\n",
    "svm_opts = dict(C=1, tol=1e-6, max_iter=int(1e6))\n",
    "svm_model = SVC(kernel='linear', **svm_opts)\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "# predict\n",
    "y_pred_svm = svm_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3449ffea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:31:49.887015Z",
     "start_time": "2024-05-12T06:31:49.863015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "         SVM      \n",
       "      metric value\n",
       "0   accuracy  0.89\n",
       "1  precision  0.90\n",
       "2     recall  0.89\n",
       "3   F1-score  0.89"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "svm_eva = func.evaluate_model(y_test, y_pred_svm)\n",
    "# change to df\n",
    "svm_df = pd.DataFrame(list(svm_eva.items()), columns=[\n",
    "                      [\"PCA\", \"PCA\"], [\"SVM\", \"SVM\"], ['metric', 'value']])\n",
    "svm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf32f23",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c38098e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:32:01.701824Z",
     "start_time": "2024-05-12T06:31:54.463706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters found:  {'C': 0.05, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# search best parameter\n",
    "param_grid = {\n",
    "    'C': [0.05, 0.08, 0.1, 1],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# model\n",
    "svm_opts = dict(tol=1e-6, max_iter=int(1e6))\n",
    "svm_model = SVC(**svm_opts)\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# print\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_svm_best = best_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "520b9443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:32:01.796836Z",
     "start_time": "2024-05-12T06:32:01.768825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "         SVM      \n",
       "      metric value\n",
       "0   accuracy  0.90\n",
       "1  precision  0.91\n",
       "2     recall  0.90\n",
       "3   F1-score  0.90"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "svm_eva_best = func.evaluate_model(y_test, y_pred_svm_best)\n",
    "# change to df\n",
    "svm_df_best = pd.DataFrame(list(svm_eva_best.items()), columns=[\n",
    "                      [\"PCA\", \"PCA\"], [\"SVM\", \"SVM\"], ['metric', 'value']])\n",
    "svm_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b79f3",
   "metadata": {},
   "source": [
    "### SVM conclusion\n",
    "可以發現 best 的結果就已經是最好的 <br>\n",
    "因此使用 best 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc853a",
   "metadata": {},
   "source": [
    "## NN--MLP\n",
    "神經網路 (Neural Network) -- 多層感知機 (Multilayer perceptron) <br>\n",
    "建模之後以 測試集 進行評估 <br>\n",
    "並且列出 4 種指標以供觀察 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b923b",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae32ed2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:32:29.498561Z",
     "start_time": "2024-05-12T06:32:26.604414Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 12.16149277\n",
      "Iteration 2, loss = 6.17901377\n",
      "Iteration 3, loss = 4.39708449\n",
      "Iteration 4, loss = 3.46573837\n",
      "Iteration 5, loss = 2.92055004\n",
      "Iteration 6, loss = 2.51078475\n",
      "Iteration 7, loss = 2.19753477\n",
      "Iteration 8, loss = 1.93325700\n",
      "Iteration 9, loss = 1.70736621\n",
      "Iteration 10, loss = 1.51792539\n",
      "Iteration 11, loss = 1.35127812\n",
      "Iteration 12, loss = 1.21933759\n",
      "Iteration 13, loss = 1.09234195\n",
      "Iteration 14, loss = 0.98303504\n",
      "Iteration 15, loss = 0.89586792\n",
      "Iteration 16, loss = 0.81347210\n",
      "Iteration 17, loss = 0.75346302\n",
      "Iteration 18, loss = 0.68941466\n",
      "Iteration 19, loss = 0.63371682\n",
      "Iteration 20, loss = 0.57687211\n",
      "Iteration 21, loss = 0.53703192\n",
      "Iteration 22, loss = 0.49643657\n",
      "Iteration 23, loss = 0.46496089\n",
      "Iteration 24, loss = 0.42824359\n",
      "Iteration 25, loss = 0.40637853\n",
      "Iteration 26, loss = 0.38301566\n",
      "Iteration 27, loss = 0.35493325\n",
      "Iteration 28, loss = 0.33589812\n",
      "Iteration 29, loss = 0.31847786\n",
      "Iteration 30, loss = 0.29794830\n",
      "Iteration 31, loss = 0.28961391\n",
      "Iteration 32, loss = 0.27111687\n",
      "Iteration 33, loss = 0.25650103\n",
      "Iteration 34, loss = 0.24591844\n",
      "Iteration 35, loss = 0.23185002\n",
      "Iteration 36, loss = 0.21560216\n",
      "Iteration 37, loss = 0.20762459\n",
      "Iteration 38, loss = 0.21088000\n",
      "Iteration 39, loss = 0.18700884\n",
      "Iteration 40, loss = 0.18254093\n",
      "Iteration 41, loss = 0.17274026\n",
      "Iteration 42, loss = 0.16251159\n",
      "Iteration 43, loss = 0.16199618\n",
      "Iteration 44, loss = 0.15462836\n",
      "Iteration 45, loss = 0.14591288\n",
      "Iteration 46, loss = 0.13593104\n",
      "Iteration 47, loss = 0.13500152\n",
      "Iteration 48, loss = 0.12793325\n",
      "Iteration 49, loss = 0.12602877\n",
      "Iteration 50, loss = 0.11994016\n",
      "Iteration 51, loss = 0.11888651\n",
      "Iteration 52, loss = 0.11028204\n",
      "Iteration 53, loss = 0.10624553\n",
      "Iteration 54, loss = 0.10982034\n",
      "Iteration 55, loss = 0.10927410\n",
      "Iteration 56, loss = 0.09860023\n",
      "Iteration 57, loss = 0.09588105\n",
      "Iteration 58, loss = 0.08989561\n",
      "Iteration 59, loss = 0.09134322\n",
      "Iteration 60, loss = 0.08567656\n",
      "Iteration 61, loss = 0.08090362\n",
      "Iteration 62, loss = 0.08011035\n",
      "Iteration 63, loss = 0.07907095\n",
      "Iteration 64, loss = 0.07413438\n",
      "Iteration 65, loss = 0.07426366\n",
      "Iteration 66, loss = 0.07186624\n",
      "Iteration 67, loss = 0.06799444\n",
      "Iteration 68, loss = 0.06589633\n",
      "Iteration 69, loss = 0.06462160\n",
      "Iteration 70, loss = 0.06294748\n",
      "Iteration 71, loss = 0.05944382\n",
      "Iteration 72, loss = 0.06267681\n",
      "Iteration 73, loss = 0.05780864\n",
      "Iteration 74, loss = 0.05368419\n",
      "Iteration 75, loss = 0.05947204\n",
      "Iteration 76, loss = 0.05581883\n",
      "Iteration 77, loss = 0.05057545\n",
      "Iteration 78, loss = 0.05142434\n",
      "Iteration 79, loss = 0.05253638\n",
      "Iteration 80, loss = 0.05228426\n",
      "Iteration 81, loss = 0.04428627\n",
      "Iteration 82, loss = 0.04345579\n",
      "Iteration 83, loss = 0.04357273\n",
      "Iteration 84, loss = 0.04200733\n",
      "Iteration 85, loss = 0.04241546\n",
      "Iteration 86, loss = 0.04220295\n",
      "Iteration 87, loss = 0.04149396\n",
      "Iteration 88, loss = 0.03663489\n",
      "Iteration 89, loss = 0.03842219\n",
      "Iteration 90, loss = 0.04580044\n",
      "Iteration 91, loss = 0.04348897\n",
      "Iteration 92, loss = 0.04168416\n",
      "Iteration 93, loss = 0.03451915\n",
      "Iteration 94, loss = 0.03414815\n",
      "Iteration 95, loss = 0.03277443\n",
      "Iteration 96, loss = 0.03172450\n",
      "Iteration 97, loss = 0.03513318\n",
      "Iteration 98, loss = 0.03253527\n",
      "Iteration 99, loss = 0.03027707\n",
      "Iteration 100, loss = 0.02984967\n",
      "Iteration 101, loss = 0.03037319\n",
      "Iteration 102, loss = 0.03034376\n",
      "Iteration 103, loss = 0.03031600\n",
      "Iteration 104, loss = 0.02779944\n",
      "Iteration 105, loss = 0.02543177\n",
      "Iteration 106, loss = 0.02621753\n",
      "Iteration 107, loss = 0.02467805\n",
      "Iteration 108, loss = 0.02659878\n",
      "Iteration 109, loss = 0.02540924\n",
      "Iteration 110, loss = 0.02559209\n",
      "Iteration 111, loss = 0.02462414\n",
      "Iteration 112, loss = 0.02448140\n",
      "Iteration 113, loss = 0.02904120\n",
      "Iteration 114, loss = 0.02946529\n",
      "Iteration 115, loss = 0.03149544\n",
      "Iteration 116, loss = 0.03248576\n",
      "Iteration 117, loss = 0.03338811\n",
      "Iteration 118, loss = 0.02414902\n",
      "Iteration 119, loss = 0.02981659\n",
      "Iteration 120, loss = 0.02702971\n",
      "Iteration 121, loss = 0.02335508\n",
      "Iteration 122, loss = 0.02414574\n",
      "Iteration 123, loss = 0.02291516\n",
      "Iteration 124, loss = 0.02638059\n",
      "Iteration 125, loss = 0.02081841\n",
      "Iteration 126, loss = 0.02765348\n",
      "Iteration 127, loss = 0.03231634\n",
      "Iteration 128, loss = 0.02556221\n",
      "Iteration 129, loss = 0.02784723\n",
      "Iteration 130, loss = 0.02349143\n",
      "Iteration 131, loss = 0.02694333\n",
      "Iteration 132, loss = 0.02437332\n",
      "Iteration 133, loss = 0.02139313\n",
      "Iteration 134, loss = 0.02291753\n",
      "Iteration 135, loss = 0.02167384\n",
      "Iteration 136, loss = 0.02096662\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# NN-MLP model & hyperparameter\n",
    "hidden_layers = (50, 100,120)\n",
    "opts = dict(hidden_layer_sizes=hidden_layers, verbose=1,\n",
    "            activation='relu', tol=1e-6, max_iter=int(1e6))\n",
    "nn_mlp_model = MLPClassifier(solver='adam', **opts)\n",
    "nn_mlp_model.fit(X_train_pca, y_train)\n",
    "# predict\n",
    "y_pred_nn_mlp = nn_mlp_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c1f1f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T06:32:30.950795Z",
     "start_time": "2024-05-12T06:32:30.917796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">NN_MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "      NN_MLP      \n",
       "      metric value\n",
       "0   accuracy  0.87\n",
       "1  precision  0.88\n",
       "2     recall  0.87\n",
       "3   F1-score  0.87"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "nn_mlp_eva = func.evaluate_model(y_test, y_pred_nn_mlp)\n",
    "# change to df\n",
    "nn_mlp_df = pd.DataFrame(list(nn_mlp_eva.items()), columns=[\n",
    "                         [\"PCA\", \"PCA\"], [\"NN_MLP\", \"NN_MLP\"], ['metric', 'value']])\n",
    "nn_mlp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e3812",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4e4cd0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:47:25.891953Z",
     "start_time": "2024-05-12T09:32:23.120353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters found:  {'activation': 'relu', 'hidden_layer_sizes': (50, 100, 120), 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# search best parameter\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 100,120)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "}\n",
    "\n",
    "# model\n",
    "opts = dict(verbose=1, tol=1e-6, max_iter=int(1e5))\n",
    "nn_mlp_model = MLPClassifier(**opts)\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(nn_mlp_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# print\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_nn_mlp_best = best_model.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79203033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:56:04.081034Z",
     "start_time": "2024-05-12T09:56:04.049030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">NN_MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "      NN_MLP      \n",
       "      metric value\n",
       "0   accuracy  0.88\n",
       "1  precision  0.89\n",
       "2     recall  0.88\n",
       "3   F1-score  0.88"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "nn_mlp_eva_best = func.evaluate_model(y_test, y_pred_nn_mlp_best)\n",
    "# change to df\n",
    "nn_mlp_df_best = pd.DataFrame(list(nn_mlp_eva_best.items()), columns=[\n",
    "                         [\"PCA\", \"PCA\"], [\"NN_MLP\", \"NN_MLP\"], ['metric', 'value']])\n",
    "nn_mlp_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17e038",
   "metadata": {},
   "source": [
    "### NN--MLP conclusion\n",
    "可以發現 best 的結果就已經是最好的 <br>\n",
    "因此使用 best 為最佳模型 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f7636",
   "metadata": {},
   "source": [
    "## NN--SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7435c77c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:39:14.282134Z",
     "start_time": "2024-05-12T12:39:14.040660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                1792      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 38)                1254      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5126 (20.02 KB)\n",
      "Trainable params: 5126 (20.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# change 1~3 to 0~2\n",
    "y_train_nn = y_train-1\n",
    "y_test_nn = y_test-1\n",
    "\n",
    "# model\n",
    "nn_seq_model = Sequential()\n",
    "nn_seq_model.add(Dense(64, activation='relu',\n",
    "                 input_shape=(X_train_pca.shape[1],)))\n",
    "nn_seq_model.add(Dense(32, activation='relu'))\n",
    "# avoid overfitting\n",
    "nn_seq_model.add(Dropout(0.2))\n",
    "nn_seq_model.add(Dense(38, activation='softmax'))\n",
    "\n",
    "# compile\n",
    "# set learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "nn_seq_model.compile(optimizer=optimizer,\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# check model\n",
    "nn_seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e9c9439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:40:01.551676Z",
     "start_time": "2024-05-12T12:39:23.162079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "49/49 [==============================] - 1s 8ms/step - loss: 14.2374 - accuracy: 0.0363 - val_loss: 5.4154 - val_accuracy: 0.0492\n",
      "Epoch 2/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 4.4999 - accuracy: 0.0506 - val_loss: 3.6294 - val_accuracy: 0.0570\n",
      "Epoch 3/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 3.5542 - accuracy: 0.0700 - val_loss: 3.4116 - val_accuracy: 0.0881\n",
      "Epoch 4/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.3706 - accuracy: 0.1012 - val_loss: 3.2733 - val_accuracy: 0.1347\n",
      "Epoch 5/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.2378 - accuracy: 0.1310 - val_loss: 3.1704 - val_accuracy: 0.1503\n",
      "Epoch 6/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.1372 - accuracy: 0.1414 - val_loss: 3.0763 - val_accuracy: 0.1710\n",
      "Epoch 7/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 3.0009 - accuracy: 0.1894 - val_loss: 2.9549 - val_accuracy: 0.2124\n",
      "Epoch 8/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 2.9110 - accuracy: 0.1978 - val_loss: 2.8199 - val_accuracy: 0.2487\n",
      "Epoch 9/250\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 2.7858 - accuracy: 0.2374 - val_loss: 2.7082 - val_accuracy: 0.2720\n",
      "Epoch 10/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 2.6701 - accuracy: 0.2724 - val_loss: 2.5977 - val_accuracy: 0.3057\n",
      "Epoch 11/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 2.5306 - accuracy: 0.3093 - val_loss: 2.4867 - val_accuracy: 0.3212\n",
      "Epoch 12/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 2.4719 - accuracy: 0.3165 - val_loss: 2.3814 - val_accuracy: 0.3368\n",
      "Epoch 13/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 2.3327 - accuracy: 0.3457 - val_loss: 2.2395 - val_accuracy: 0.3705\n",
      "Epoch 14/250\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 2.1955 - accuracy: 0.3898 - val_loss: 2.1272 - val_accuracy: 0.4093\n",
      "Epoch 15/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 2.0855 - accuracy: 0.4105 - val_loss: 2.0127 - val_accuracy: 0.4482\n",
      "Epoch 16/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 1.9686 - accuracy: 0.4533 - val_loss: 1.8843 - val_accuracy: 0.4611\n",
      "Epoch 17/250\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.8915 - accuracy: 0.4624 - val_loss: 1.8025 - val_accuracy: 0.4870\n",
      "Epoch 18/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.8115 - accuracy: 0.4818 - val_loss: 1.7057 - val_accuracy: 0.5389\n",
      "Epoch 19/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.7232 - accuracy: 0.5169 - val_loss: 1.6241 - val_accuracy: 0.5699\n",
      "Epoch 20/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.6174 - accuracy: 0.5350 - val_loss: 1.5541 - val_accuracy: 0.5648\n",
      "Epoch 21/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.5759 - accuracy: 0.5525 - val_loss: 1.5113 - val_accuracy: 0.6036\n",
      "Epoch 22/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 0.5590 - val_loss: 1.4380 - val_accuracy: 0.6062\n",
      "Epoch 23/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.4539 - accuracy: 0.5850 - val_loss: 1.3868 - val_accuracy: 0.6218\n",
      "Epoch 24/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 1.3455 - accuracy: 0.6167 - val_loss: 1.3700 - val_accuracy: 0.6244\n",
      "Epoch 25/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.3635 - accuracy: 0.6038 - val_loss: 1.3721 - val_accuracy: 0.6244\n",
      "Epoch 26/250\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.2747 - accuracy: 0.6213 - val_loss: 1.2689 - val_accuracy: 0.6580\n",
      "Epoch 27/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.2448 - accuracy: 0.6414 - val_loss: 1.2143 - val_accuracy: 0.6813\n",
      "Epoch 28/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.1442 - accuracy: 0.6796 - val_loss: 1.1791 - val_accuracy: 0.6891\n",
      "Epoch 29/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.1838 - accuracy: 0.6453 - val_loss: 1.1511 - val_accuracy: 0.6658\n",
      "Epoch 30/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.1181 - accuracy: 0.6654 - val_loss: 1.0812 - val_accuracy: 0.6891\n",
      "Epoch 31/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 1.0645 - accuracy: 0.6803 - val_loss: 1.0786 - val_accuracy: 0.6839\n",
      "Epoch 32/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 1.0420 - accuracy: 0.6965 - val_loss: 1.0440 - val_accuracy: 0.6969\n",
      "Epoch 33/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.9778 - accuracy: 0.7049 - val_loss: 0.9704 - val_accuracy: 0.6917\n",
      "Epoch 34/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.0060 - accuracy: 0.6946 - val_loss: 1.0189 - val_accuracy: 0.6865\n",
      "Epoch 35/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.7270 - val_loss: 0.9652 - val_accuracy: 0.7073\n",
      "Epoch 36/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8781 - accuracy: 0.7270 - val_loss: 0.9837 - val_accuracy: 0.6917\n",
      "Epoch 37/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8668 - accuracy: 0.7419 - val_loss: 0.9015 - val_accuracy: 0.7280\n",
      "Epoch 38/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.7510 - val_loss: 0.8837 - val_accuracy: 0.7435\n",
      "Epoch 39/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8236 - accuracy: 0.7451 - val_loss: 0.9143 - val_accuracy: 0.7254\n",
      "Epoch 40/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8108 - accuracy: 0.7523 - val_loss: 0.9022 - val_accuracy: 0.7487\n",
      "Epoch 41/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7891 - accuracy: 0.7464 - val_loss: 0.8561 - val_accuracy: 0.7617\n",
      "Epoch 42/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7646 - val_loss: 0.8420 - val_accuracy: 0.7513\n",
      "Epoch 43/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.7795 - val_loss: 0.8345 - val_accuracy: 0.7668\n",
      "Epoch 44/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.7892 - val_loss: 0.8133 - val_accuracy: 0.7772\n",
      "Epoch 45/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7931 - val_loss: 0.8075 - val_accuracy: 0.7617\n",
      "Epoch 46/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.7847 - val_loss: 0.8662 - val_accuracy: 0.7720\n",
      "Epoch 47/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.8035 - val_loss: 0.7604 - val_accuracy: 0.7720\n",
      "Epoch 48/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7957 - val_loss: 0.7737 - val_accuracy: 0.8083\n",
      "Epoch 49/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8100 - val_loss: 0.7782 - val_accuracy: 0.7979\n",
      "Epoch 50/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.8191 - val_loss: 0.8063 - val_accuracy: 0.7591\n",
      "Epoch 51/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.8139 - val_loss: 0.7929 - val_accuracy: 0.7927\n",
      "Epoch 52/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.8178 - val_loss: 0.7399 - val_accuracy: 0.7979\n",
      "Epoch 53/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.8470 - val_loss: 0.7428 - val_accuracy: 0.7902\n",
      "Epoch 54/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8268 - val_loss: 0.7575 - val_accuracy: 0.7953\n",
      "Epoch 55/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8275 - val_loss: 0.6974 - val_accuracy: 0.8135\n",
      "Epoch 56/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8437 - val_loss: 0.7001 - val_accuracy: 0.8316\n",
      "Epoch 57/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8340 - val_loss: 0.7663 - val_accuracy: 0.7953\n",
      "Epoch 58/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8502 - val_loss: 0.7026 - val_accuracy: 0.8083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8521 - val_loss: 0.7099 - val_accuracy: 0.8005\n",
      "Epoch 60/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8586 - val_loss: 0.6707 - val_accuracy: 0.8187\n",
      "Epoch 61/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8528 - val_loss: 0.6805 - val_accuracy: 0.8083\n",
      "Epoch 62/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8528 - val_loss: 0.6609 - val_accuracy: 0.8187\n",
      "Epoch 63/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8638 - val_loss: 0.6882 - val_accuracy: 0.8187\n",
      "Epoch 64/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8489 - val_loss: 0.6711 - val_accuracy: 0.8109\n",
      "Epoch 65/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8528 - val_loss: 0.6862 - val_accuracy: 0.8238\n",
      "Epoch 66/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8599 - val_loss: 0.6810 - val_accuracy: 0.8264\n",
      "Epoch 67/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8580 - val_loss: 0.6516 - val_accuracy: 0.8290\n",
      "Epoch 68/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8684 - val_loss: 0.6567 - val_accuracy: 0.8342\n",
      "Epoch 69/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8820 - val_loss: 0.6308 - val_accuracy: 0.8316\n",
      "Epoch 70/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8696 - val_loss: 0.6492 - val_accuracy: 0.8368\n",
      "Epoch 71/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8774 - val_loss: 0.6353 - val_accuracy: 0.8238\n",
      "Epoch 72/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8625 - val_loss: 0.6100 - val_accuracy: 0.8290\n",
      "Epoch 73/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8735 - val_loss: 0.6310 - val_accuracy: 0.8264\n",
      "Epoch 74/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8612 - val_loss: 0.6145 - val_accuracy: 0.8316\n",
      "Epoch 75/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8703 - val_loss: 0.6061 - val_accuracy: 0.8420\n",
      "Epoch 76/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8755 - val_loss: 0.6379 - val_accuracy: 0.8264\n",
      "Epoch 77/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8852 - val_loss: 0.6224 - val_accuracy: 0.8238\n",
      "Epoch 78/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8872 - val_loss: 0.6285 - val_accuracy: 0.8316\n",
      "Epoch 79/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8813 - val_loss: 0.5852 - val_accuracy: 0.8394\n",
      "Epoch 80/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8794 - val_loss: 0.5883 - val_accuracy: 0.8394\n",
      "Epoch 81/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.8865 - val_loss: 0.6442 - val_accuracy: 0.8316\n",
      "Epoch 82/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8826 - val_loss: 0.5993 - val_accuracy: 0.8394\n",
      "Epoch 83/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8982 - val_loss: 0.6118 - val_accuracy: 0.8472\n",
      "Epoch 84/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.9021 - val_loss: 0.6267 - val_accuracy: 0.8316\n",
      "Epoch 85/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8878 - val_loss: 0.6093 - val_accuracy: 0.8472\n",
      "Epoch 86/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8988 - val_loss: 0.6125 - val_accuracy: 0.8420\n",
      "Epoch 87/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8917 - val_loss: 0.6122 - val_accuracy: 0.8472\n",
      "Epoch 88/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8969 - val_loss: 0.5770 - val_accuracy: 0.8523\n",
      "Epoch 89/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.9014 - val_loss: 0.6322 - val_accuracy: 0.8394\n",
      "Epoch 90/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.9021 - val_loss: 0.5888 - val_accuracy: 0.8394\n",
      "Epoch 91/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.9034 - val_loss: 0.6088 - val_accuracy: 0.8368\n",
      "Epoch 92/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.9034 - val_loss: 0.6042 - val_accuracy: 0.8497\n",
      "Epoch 93/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9034 - val_loss: 0.6451 - val_accuracy: 0.8446\n",
      "Epoch 94/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.9034 - val_loss: 0.6399 - val_accuracy: 0.8523\n",
      "Epoch 95/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.9105 - val_loss: 0.5887 - val_accuracy: 0.8394\n",
      "Epoch 96/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.9021 - val_loss: 0.6349 - val_accuracy: 0.8394\n",
      "Epoch 97/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.9014 - val_loss: 0.6384 - val_accuracy: 0.8264\n",
      "Epoch 98/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.9053 - val_loss: 0.5815 - val_accuracy: 0.8342\n",
      "Epoch 99/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9183 - val_loss: 0.6342 - val_accuracy: 0.8316\n",
      "Epoch 100/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.9176 - val_loss: 0.6166 - val_accuracy: 0.8523\n",
      "Epoch 101/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.9196 - val_loss: 0.5912 - val_accuracy: 0.8497\n",
      "Epoch 102/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9047 - val_loss: 0.5981 - val_accuracy: 0.8316\n",
      "Epoch 103/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9157 - val_loss: 0.5647 - val_accuracy: 0.8549\n",
      "Epoch 104/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.9170 - val_loss: 0.6032 - val_accuracy: 0.8472\n",
      "Epoch 105/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9332 - val_loss: 0.5757 - val_accuracy: 0.8446\n",
      "Epoch 106/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.9118 - val_loss: 0.6070 - val_accuracy: 0.8497\n",
      "Epoch 107/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9241 - val_loss: 0.6469 - val_accuracy: 0.8497\n",
      "Epoch 108/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9099 - val_loss: 0.5811 - val_accuracy: 0.8575\n",
      "Epoch 109/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9118 - val_loss: 0.5623 - val_accuracy: 0.8472\n",
      "Epoch 110/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.9118 - val_loss: 0.6000 - val_accuracy: 0.8653\n",
      "Epoch 111/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2436 - accuracy: 0.9228 - val_loss: 0.6295 - val_accuracy: 0.8523\n",
      "Epoch 112/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9189 - val_loss: 0.5604 - val_accuracy: 0.8679\n",
      "Epoch 113/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2430 - accuracy: 0.9157 - val_loss: 0.5619 - val_accuracy: 0.8808\n",
      "Epoch 114/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9280 - val_loss: 0.5918 - val_accuracy: 0.8575\n",
      "Epoch 115/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9228 - val_loss: 0.6162 - val_accuracy: 0.8627\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9150 - val_loss: 0.6813 - val_accuracy: 0.8679\n",
      "Epoch 117/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9222 - val_loss: 0.6629 - val_accuracy: 0.8575\n",
      "Epoch 118/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9261 - val_loss: 0.5845 - val_accuracy: 0.8679\n",
      "Epoch 119/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9339 - val_loss: 0.6100 - val_accuracy: 0.8731\n",
      "Epoch 120/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9280 - val_loss: 0.5576 - val_accuracy: 0.8601\n",
      "Epoch 121/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9293 - val_loss: 0.5995 - val_accuracy: 0.8756\n",
      "Epoch 122/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9235 - val_loss: 0.6126 - val_accuracy: 0.8705\n",
      "Epoch 123/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9228 - val_loss: 0.5291 - val_accuracy: 0.8860\n",
      "Epoch 124/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9300 - val_loss: 0.5548 - val_accuracy: 0.8627\n",
      "Epoch 125/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9377 - val_loss: 0.5351 - val_accuracy: 0.8679\n",
      "Epoch 126/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9339 - val_loss: 0.5807 - val_accuracy: 0.8679\n",
      "Epoch 127/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9261 - val_loss: 0.5266 - val_accuracy: 0.8653\n",
      "Epoch 128/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.9280 - val_loss: 0.5325 - val_accuracy: 0.8653\n",
      "Epoch 129/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.9196 - val_loss: 0.5301 - val_accuracy: 0.8627\n",
      "Epoch 130/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9390 - val_loss: 0.5152 - val_accuracy: 0.8523\n",
      "Epoch 131/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9313 - val_loss: 0.5598 - val_accuracy: 0.8653\n",
      "Epoch 132/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9326 - val_loss: 0.5344 - val_accuracy: 0.8756\n",
      "Epoch 133/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9313 - val_loss: 0.5495 - val_accuracy: 0.8653\n",
      "Epoch 134/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9261 - val_loss: 0.5804 - val_accuracy: 0.8782\n",
      "Epoch 135/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9377 - val_loss: 0.5284 - val_accuracy: 0.8756\n",
      "Epoch 136/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9274 - val_loss: 0.4825 - val_accuracy: 0.8860\n",
      "Epoch 137/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.5186 - val_accuracy: 0.8886\n",
      "Epoch 138/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9332 - val_loss: 0.5294 - val_accuracy: 0.8731\n",
      "Epoch 139/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9261 - val_loss: 0.5379 - val_accuracy: 0.8782\n",
      "Epoch 140/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9403 - val_loss: 0.5891 - val_accuracy: 0.8705\n",
      "Epoch 141/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9326 - val_loss: 0.5484 - val_accuracy: 0.8834\n",
      "Epoch 142/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9436 - val_loss: 0.5016 - val_accuracy: 0.8782\n",
      "Epoch 143/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9390 - val_loss: 0.5756 - val_accuracy: 0.8705\n",
      "Epoch 144/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9416 - val_loss: 0.5525 - val_accuracy: 0.8990\n",
      "Epoch 145/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9410 - val_loss: 0.5107 - val_accuracy: 0.8938\n",
      "Epoch 146/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9429 - val_loss: 0.5355 - val_accuracy: 0.8886\n",
      "Epoch 147/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9475 - val_loss: 0.5450 - val_accuracy: 0.8860\n",
      "Epoch 148/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9371 - val_loss: 0.5192 - val_accuracy: 0.8834\n",
      "Epoch 149/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9377 - val_loss: 0.5266 - val_accuracy: 0.8808\n",
      "Epoch 150/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9455 - val_loss: 0.5456 - val_accuracy: 0.8860\n",
      "Epoch 151/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9423 - val_loss: 0.5305 - val_accuracy: 0.8834\n",
      "Epoch 152/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9293 - val_loss: 0.5835 - val_accuracy: 0.8860\n",
      "Epoch 153/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9377 - val_loss: 0.5631 - val_accuracy: 0.8653\n",
      "Epoch 154/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9520 - val_loss: 0.5273 - val_accuracy: 0.8990\n",
      "Epoch 155/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9364 - val_loss: 0.5146 - val_accuracy: 0.8912\n",
      "Epoch 156/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9371 - val_loss: 0.5262 - val_accuracy: 0.8756\n",
      "Epoch 157/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9384 - val_loss: 0.4983 - val_accuracy: 0.8938\n",
      "Epoch 158/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9358 - val_loss: 0.4913 - val_accuracy: 0.8756\n",
      "Epoch 159/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9462 - val_loss: 0.5334 - val_accuracy: 0.8860\n",
      "Epoch 160/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.9481 - val_loss: 0.4856 - val_accuracy: 0.8964\n",
      "Epoch 161/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9488 - val_loss: 0.5489 - val_accuracy: 0.9016\n",
      "Epoch 162/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9410 - val_loss: 0.5485 - val_accuracy: 0.8860\n",
      "Epoch 163/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9436 - val_loss: 0.5889 - val_accuracy: 0.8679\n",
      "Epoch 164/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9455 - val_loss: 0.6368 - val_accuracy: 0.8756\n",
      "Epoch 165/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9364 - val_loss: 0.5937 - val_accuracy: 0.8860\n",
      "Epoch 166/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 0.5754 - val_accuracy: 0.8731\n",
      "Epoch 167/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9527 - val_loss: 0.5735 - val_accuracy: 0.8938\n",
      "Epoch 168/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9468 - val_loss: 0.5943 - val_accuracy: 0.8782\n",
      "Epoch 169/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9410 - val_loss: 0.5715 - val_accuracy: 0.8834\n",
      "Epoch 170/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9488 - val_loss: 0.5596 - val_accuracy: 0.8756\n",
      "Epoch 171/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9390 - val_loss: 0.5910 - val_accuracy: 0.8912\n",
      "Epoch 172/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9481 - val_loss: 0.5698 - val_accuracy: 0.8886\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9455 - val_loss: 0.5604 - val_accuracy: 0.8834\n",
      "Epoch 174/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9475 - val_loss: 0.5777 - val_accuracy: 0.8860\n",
      "Epoch 175/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9455 - val_loss: 0.4709 - val_accuracy: 0.8886\n",
      "Epoch 176/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9501 - val_loss: 0.4910 - val_accuracy: 0.8886\n",
      "Epoch 177/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9449 - val_loss: 0.5165 - val_accuracy: 0.8938\n",
      "Epoch 178/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9507 - val_loss: 0.5041 - val_accuracy: 0.8938\n",
      "Epoch 179/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9494 - val_loss: 0.5320 - val_accuracy: 0.9016\n",
      "Epoch 180/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9494 - val_loss: 0.5584 - val_accuracy: 0.8964\n",
      "Epoch 181/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9527 - val_loss: 0.5879 - val_accuracy: 0.8808\n",
      "Epoch 182/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9501 - val_loss: 0.5933 - val_accuracy: 0.8679\n",
      "Epoch 183/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9514 - val_loss: 0.5532 - val_accuracy: 0.8860\n",
      "Epoch 184/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9475 - val_loss: 0.5739 - val_accuracy: 0.8912\n",
      "Epoch 185/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9591 - val_loss: 0.6126 - val_accuracy: 0.8834\n",
      "Epoch 186/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9507 - val_loss: 0.5951 - val_accuracy: 0.8886\n",
      "Epoch 187/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9507 - val_loss: 0.5724 - val_accuracy: 0.8938\n",
      "Epoch 188/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9481 - val_loss: 0.5694 - val_accuracy: 0.8886\n",
      "Epoch 189/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9533 - val_loss: 0.5570 - val_accuracy: 0.8808\n",
      "Epoch 190/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9520 - val_loss: 0.5397 - val_accuracy: 0.8834\n",
      "Epoch 191/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9507 - val_loss: 0.5276 - val_accuracy: 0.8938\n",
      "Epoch 192/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9507 - val_loss: 0.5620 - val_accuracy: 0.8964\n",
      "Epoch 193/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9578 - val_loss: 0.5873 - val_accuracy: 0.8782\n",
      "Epoch 194/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9533 - val_loss: 0.5913 - val_accuracy: 0.8912\n",
      "Epoch 195/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9527 - val_loss: 0.5138 - val_accuracy: 0.9041\n",
      "Epoch 196/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9520 - val_loss: 0.4973 - val_accuracy: 0.9016\n",
      "Epoch 197/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9520 - val_loss: 0.5630 - val_accuracy: 0.9119\n",
      "Epoch 198/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9598 - val_loss: 0.5406 - val_accuracy: 0.8912\n",
      "Epoch 199/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9553 - val_loss: 0.5423 - val_accuracy: 0.9016\n",
      "Epoch 200/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9507 - val_loss: 0.4904 - val_accuracy: 0.9016\n",
      "Epoch 201/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9565 - val_loss: 0.5893 - val_accuracy: 0.8808\n",
      "Epoch 202/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9468 - val_loss: 0.5571 - val_accuracy: 0.8912\n",
      "Epoch 203/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9585 - val_loss: 0.6230 - val_accuracy: 0.8834\n",
      "Epoch 204/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9650 - val_loss: 0.6003 - val_accuracy: 0.9016\n",
      "Epoch 205/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9624 - val_loss: 0.6659 - val_accuracy: 0.8886\n",
      "Epoch 206/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9598 - val_loss: 0.5993 - val_accuracy: 0.8886\n",
      "Epoch 207/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9449 - val_loss: 0.5627 - val_accuracy: 0.9067\n",
      "Epoch 208/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9591 - val_loss: 0.5760 - val_accuracy: 0.8990\n",
      "Epoch 209/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9611 - val_loss: 0.5301 - val_accuracy: 0.9119\n",
      "Epoch 210/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9578 - val_loss: 0.5064 - val_accuracy: 0.9067\n",
      "Epoch 211/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9559 - val_loss: 0.5315 - val_accuracy: 0.8964\n",
      "Epoch 212/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9559 - val_loss: 0.6056 - val_accuracy: 0.8964\n",
      "Epoch 213/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9501 - val_loss: 0.5659 - val_accuracy: 0.8990\n",
      "Epoch 214/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9520 - val_loss: 0.5319 - val_accuracy: 0.8912\n",
      "Epoch 215/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9533 - val_loss: 0.6016 - val_accuracy: 0.9093\n",
      "Epoch 216/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9604 - val_loss: 0.6050 - val_accuracy: 0.9041\n",
      "Epoch 217/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9682 - val_loss: 0.6421 - val_accuracy: 0.8808\n",
      "Epoch 218/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9572 - val_loss: 0.6305 - val_accuracy: 0.8912\n",
      "Epoch 219/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9565 - val_loss: 0.6157 - val_accuracy: 0.8990\n",
      "Epoch 220/250\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1382 - accuracy: 0.9591 - val_loss: 0.5767 - val_accuracy: 0.8912\n",
      "Epoch 221/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9514 - val_loss: 0.6445 - val_accuracy: 0.8886\n",
      "Epoch 222/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9598 - val_loss: 0.6099 - val_accuracy: 0.9041\n",
      "Epoch 223/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9585 - val_loss: 0.6713 - val_accuracy: 0.8912\n",
      "Epoch 224/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9682 - val_loss: 0.6188 - val_accuracy: 0.8912\n",
      "Epoch 225/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9546 - val_loss: 0.6162 - val_accuracy: 0.8938\n",
      "Epoch 226/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9591 - val_loss: 0.6029 - val_accuracy: 0.8886\n",
      "Epoch 227/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9611 - val_loss: 0.5529 - val_accuracy: 0.9171\n",
      "Epoch 228/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9520 - val_loss: 0.5385 - val_accuracy: 0.9223\n",
      "Epoch 229/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9624 - val_loss: 0.5512 - val_accuracy: 0.9093\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9553 - val_loss: 0.5628 - val_accuracy: 0.8964\n",
      "Epoch 231/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9442 - val_loss: 0.5046 - val_accuracy: 0.9093\n",
      "Epoch 232/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9540 - val_loss: 0.5623 - val_accuracy: 0.9016\n",
      "Epoch 233/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9481 - val_loss: 0.6242 - val_accuracy: 0.8912\n",
      "Epoch 234/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9572 - val_loss: 0.5455 - val_accuracy: 0.9067\n",
      "Epoch 235/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9617 - val_loss: 0.5361 - val_accuracy: 0.8964\n",
      "Epoch 236/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9624 - val_loss: 0.5900 - val_accuracy: 0.8938\n",
      "Epoch 237/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9624 - val_loss: 0.5775 - val_accuracy: 0.8990\n",
      "Epoch 238/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9689 - val_loss: 0.5007 - val_accuracy: 0.9145\n",
      "Epoch 239/250\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9598 - val_loss: 0.5340 - val_accuracy: 0.9041\n",
      "Epoch 240/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9676 - val_loss: 0.5455 - val_accuracy: 0.9016\n",
      "Epoch 241/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9650 - val_loss: 0.5202 - val_accuracy: 0.8990\n",
      "Epoch 242/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9611 - val_loss: 0.6298 - val_accuracy: 0.8834\n",
      "Epoch 243/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9540 - val_loss: 0.5577 - val_accuracy: 0.9016\n",
      "Epoch 244/250\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9540 - val_loss: 0.5443 - val_accuracy: 0.8938\n",
      "Epoch 245/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9533 - val_loss: 0.5832 - val_accuracy: 0.8990\n",
      "Epoch 246/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9578 - val_loss: 0.5564 - val_accuracy: 0.9016\n",
      "Epoch 247/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9598 - val_loss: 0.5168 - val_accuracy: 0.9041\n",
      "Epoch 248/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9663 - val_loss: 0.5364 - val_accuracy: 0.9093\n",
      "Epoch 249/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9656 - val_loss: 0.5454 - val_accuracy: 0.9093\n",
      "Epoch 250/250\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9624 - val_loss: 0.6239 - val_accuracy: 0.8860\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = nn_seq_model.fit(X_train_pca, y_train_nn,\n",
    "                           epochs=250, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24f05773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:40:03.488333Z",
     "start_time": "2024-05-12T12:40:03.265517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.5134116411209106\n",
      "accuracy : 0.8962655663490295\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_loss, test_accuracy = nn_seq_model.evaluate(\n",
    "    X_test_pca, y_test_nn, verbose=0)\n",
    "y_pred_prob = nn_seq_model.predict(X_test_pca, verbose=0)\n",
    "y_pred_nn_seq = np.argmax(y_pred_prob, axis=1)\n",
    "print(\"loss :\", test_loss)\n",
    "print(\"accuracy :\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9621306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:40:04.286949Z",
     "start_time": "2024-05-12T12:40:04.241368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">NN_SEQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA      \n",
       "      NN_SEQ      \n",
       "      metric value\n",
       "0   accuracy   0.9\n",
       "1  precision   0.9\n",
       "2     recall   0.9\n",
       "3   F1-score   0.9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "nn_seq_eva = func.evaluate_model(y_test_nn, y_pred_nn_seq)\n",
    "# change to df\n",
    "nn_seq_df = pd.DataFrame(list(nn_seq_eva.items()), columns=[\n",
    "                         [\"PCA\", \"PCA\"], [\"NN_SEQ\", \"NN_SEQ\"], ['metric', 'value']])\n",
    "nn_seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b604ebb",
   "metadata": {},
   "source": [
    "## compare evaluation of pca data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11e97818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:40:13.807075Z",
     "start_time": "2024-05-12T12:40:13.776951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MLR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN_MLP</th>\n",
       "      <th>NN_SEQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PCA                    \n",
       "            MLR   SVM NN_MLP NN_SEQ\n",
       "          value value  value  value\n",
       "metric                             \n",
       "accuracy   0.88  0.90   0.87    0.9\n",
       "precision  0.89  0.91   0.88    0.9\n",
       "recall     0.88  0.90   0.87    0.9\n",
       "F1-score   0.88  0.90   0.87    0.9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine df together\n",
    "mlr_df_copy = mlr_df.copy()\n",
    "svm_df_best_copy = svm_df_best.copy()\n",
    "nn_mlp_df_copy = nn_mlp_df.copy()\n",
    "nn_seq_df_copy = nn_seq_df.copy()\n",
    "# del same col\n",
    "svm_df_best_copy.drop((\"PCA\", \"SVM\", \"metric\"), axis=1, inplace=True)\n",
    "nn_mlp_df_copy.drop((\"PCA\", \"NN_MLP\", \"metric\"), axis=1, inplace=True)\n",
    "nn_seq_df_copy.drop((\"PCA\", \"NN_SEQ\", \"metric\"), axis=1, inplace=True)\n",
    "\n",
    "# combine\n",
    "final_df_pca = pd.concat(\n",
    "    [mlr_df_copy, svm_df_best_copy, nn_mlp_df_copy, nn_seq_df_copy], axis=1)\n",
    "# set \"metric\" to index\n",
    "final_df_pca.set_index((\"PCA\", \"MLR\", \"metric\"), inplace=True)\n",
    "final_df_pca = final_df_pca.rename_axis(\"metric\")\n",
    "\n",
    "# show\n",
    "final_df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0f79f",
   "metadata": {},
   "source": [
    "## model of pca data conclusion\n",
    "可以看出總體來說 SVM、NN_SEQ 模型的表現是最好的 <br>\n",
    "雖然得到的分數與剩下的沒有差距太大 <br>\n",
    "不過他們所運行時間並不會太長 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455157c1",
   "metadata": {},
   "source": [
    "# final conclusion\n",
    "把上述所有的評估指標組合一起觀察 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0b165ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T12:40:15.226461Z",
     "start_time": "2024-05-12T12:40:15.199756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">standard</th>\n",
       "      <th colspan=\"4\" halign=\"left\">PCA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MLR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN_MLP</th>\n",
       "      <th>NN_SEQ</th>\n",
       "      <th>MLR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN_MLP</th>\n",
       "      <th>NN_SEQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          standard                       PCA                    \n",
       "               MLR   SVM NN_MLP NN_SEQ   MLR   SVM NN_MLP NN_SEQ\n",
       "             value value  value  value value value  value  value\n",
       "metric                                                          \n",
       "accuracy      0.98  0.94   0.96   0.91  0.88  0.90   0.87    0.9\n",
       "precision     0.98  0.94   0.96   0.92  0.89  0.91   0.88    0.9\n",
       "recall        0.98  0.94   0.96   0.91  0.88  0.90   0.87    0.9\n",
       "F1-score      0.97  0.94   0.96   0.91  0.88  0.90   0.87    0.9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat(\n",
    "    [final_df_standard, final_df_pca], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131b6be",
   "metadata": {},
   "source": [
    "可以發現到其實資料集進行標準化得到的評估指標相較於 PCA 優異了一點 <br>\n",
    "有可能是因為 PCA 時把一些特徵忽略掉所導致的 <br>\n",
    "但如果以運行時間來觀察的話 <br>\n",
    "能夠發現經過 PCA 後的資料在 fit 模型時花費的時間比較短 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a6014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e429b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8e06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
